---
title: "sample_expr_readme"
author: "Will Schuerman"
date: "December 22, 2014"
output: html_document

---

### Experiment summary:

This project is based on experiments performed in collaboration between the Max Planck Institute for Psycholinguistics and the University of California, San Francisco. All data utilized in this script have been generated by the author for the purposes of demonstration. 

Altered auditory feedback involves manipulating speech sounds, such as particular vowel frequencies, in real-time to create a mismatch between a speaker's normal articulations and what the speaker actually hears being produced. This can lead to adaptation in how a speaker produces a given sound, such as the vowel /i/ ('ee'). It is known that in speech perception, the interpretation of speech sounds can be contextually-dependent; an ambiguous sound somewhere between /s/ ('s') and /S/ ('esh') is more likely to be perceived as /S/ if it is followed by a vowel like /i/, and as /s/ if it followed by /u/. It has been proposed that the change in motor-to-sound mappings induced by altered auditory feedback are not generalizable to other speech sounds. To test whether these changes are local and global, this experiment compares the identification of ambiguous sounds between /s/ and /S/ followed by the vowel /i/ after the participant has been exposed to unaltered and altered auditory feedback.

### Overview of the experimental procedure.
In this experiment, the participant performed two tasks: a Production task and an Identification task. Each session began with an Identification task, followed by a Production task, followed by an Identification task, for a total of 4 Production tasks and 5 Identification tasks completed in each session. We predicted that exposure to altered auditory feedback would affect the identification of contextually-dependent speech sounds drawn from a computer generated continuuum. 

In the Production task, the participant was presented with 26 words containing the vowel /i/ and asked to read them aloud. In the first session ("NoPert"), the participant heard their unaltered voice via headphones. In the second session ("YesPert"), the resonating frequencies of the participants voice were shifted backwards in the vowel space. The shift occurred slowly to prevent the participant from noticing. The shift began on the first trial of the second block, slowly increasing until the last trial of the second block. The shift then persisted at full strength for the following two blocks.

In the Identification task, the participant was asked identify via keyboard whether they heard a speaker producing the word "see" (response button 1) or the word "she" (response button 2). The presented stimuli were drawn from a continuum between "see" and "she", generated via additive synthesis. 

### Results

The graphs below show the measurements for the first and second resonant frequencies of the voice over the course of the experiment. Red crosses represent what the participant actually produced, while blue crosses indicate the frequency of the auditory feedback transmitted over headphones (what the participant heard themselves saying). The solid line indicates the mean of the first production block, and is utilized as a baseline of comparison for all subsequent production blocks.

The large circles indicate the proportion of "she" responses obtained during the identification tasks before and after each production block. 

In the first (unaltered feedback) session, input and output are identical throughout the experiment.

```{r, echo=FALSE}
PlotBuffers(sess="NoPert")
```

In the second (altered feedback) session, the first frequency is shifted upwards (higher than normal) and the second frequency is shifted downwards (lower than normal). Decreasing the dispersion between these two frequencies results in a vowel that sounds more rounded and farther back in the vowelspace than the speaker intended. 

```{r, echo=FALSE}
PlotBuffers(sess="YesPert")
```

These graphs show that in the first session, the participant experienced a steady decrease in the number of stimuli perceived as "she." In the second session, the proportion of "she" responses remains relatively stable. 

Another method of comparing performance in the two sessions is to determine the stimulus number at which the participant switched from reporting hearing "see" to reporting hearing "she". 

The graph below contrasts performance in "Block 4" of each session. The first column shows the participant's responses to each stimulus, indicated by the black circles. Red asterisks represent linearly interpolated data points between the participant's responses. The second column shows the results of fitting a sigmoid-curve to the interpolated responses. The dotted line indicates the 50% response point, i.e. the stimulus number at which the participant stopped hearing "see" and started hearing "she".

```{r, echo=FALSE}
PlotIdent(1,4)
```

These results suggest that, for this participant, there was no effect of altered auditory feedback on the interwoven identification tasks. 

require(knitr)
knit2html("sample_expr_readme.Rmd")
