tmp$trialb = rep(c(1:26), max(tmp$V13)+1)
tmp$subj <- substr(x = text.file, start =1, stop = regexpr(pattern = "_", text.file)-1)
if(length(grep("YesPert", text.file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
names(tmp) <-c('in.f1.25', 'in.f2.25', 'out.f1.25', 'out.f2.25',
'in.f1.50', 'in.f2.50', 'out.f1.50', 'out.f2.50',
'in.f1.75', 'in.f2.75', 'out.f1.75', 'out.f2.75',
'block', 'trial', 'trialb', 'subj', 'session')
prod.data <- rbind(prod.data, tmp)
}
prod.data = prod.data[-1,]
# Increase raw block count to align with experiment procedure
prod.data$block = prod.data$block+1
# get rid of NaN trials
prod.data <- prod.data[complete.cases(prod.data),]
# get rid of 'S' in subject
prod.data$subj <- substr(prod.data$subj, start=2, stop=3)
prod.data$subj <- factor(prod.data$subj)
# Convert to factors
prod.data$subj <- factor(prod.data$subj)
prod.data$session <- factor(prod.data$session)
# restrict data to measurements taken at vowel midpoint.
prod.data <- prod.data[,c("subj", "session", "block","trialb","trial","in.f1.50","out.f1.50","in.f2.50","out.f2.50")]
# remove outliers, by scaling the the inbuffers and outbuffers, and discarding anything greater than 3 standard deviations from average
prod.data <- ddply(prod.data, c("subj", "session"), transform, z.in.f2.50 = scale(in.f2.50))
prod.data <- ddply(prod.data, c("subj", "session"), transform, z.in.f1.50 = scale(in.f1.50))
total.cases <- nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f1.50 < 3 & prod.data$z.in.f1.50 > -3),]
f1.outliers <- total.cases - nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f2.50 < 3 & prod.data$z.in.f2.50 > -3),]
f2.outliers <- total.cases-f1.outliers-nrow(prod.data)
# calculate dispersion between first and second resonant frequencies
prod.data$in.dispersion <- prod.data$in.f2.50 - prod.data$in.f1.50
prod.data$out.dispersion <- prod.data$out.f2.50 - prod.data$out.f1.50
prod.data <- ddply(prod.data, c("subj", "session"), transform, z.in.dispersion = scale(in.dispersion))
# calculate baselines as average F1 and F2 in the first block.
prod.data$baseline.f1.50 <- 0
prod.data$baseline.f2.50 <- 0
prod.data$baseline.dispersion <- 0
for(session in levels(prod.data$session)){
for(subj in levels(prod.data$subj)){
prod.data$baseline.f1.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f1.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.f2.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f2.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.dispersion[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.dispersion'][which(prod.data$block==1)], na.rm=T)
}
}
# Read in identification data
text.files.identification <- dir("Identification_data/")
ident.data = data.frame(1,1,1,1,1,'NoPert')
names(ident.data) <- c("subj", "trial", "stimulus" , "response", "block", "session")
for(text_file in text.files.identification){
tmp <- read.table(file=paste("Identification_data/", text_file, sep=""), header = T)
if(length(grep("YESPERT", text_file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
ident.data <- rbind(ident.data, tmp)
browser()
}
ident.data = ident.data[-1,]
# move block down by one, so that block 0 is the pre-test
ident.data$block <- ident.data$block-1
# Convert to factors
ident.data$subj <- factor(ident.data$subj)
ident.data$trial <- factor(ident.data$trial)
ident.data$session <- factor(ident.data$session)
ident.data$block <- factor(ident.data$block)
# fix times when participants definitely hit the wrong button
ident.data$response[which(ident.data$response==2 & ident.data$stimulus == 0)] <- 1
ident.data$response[which(ident.data$response==1 & ident.data$stimulus == 100)] <- 2
# fix times when participants hit the number 3
ident.data$response[which(ident.data$response==3)] <- 2
# subtract 1 from the responses to make it 0 and 1
ident.data$response <- ident.data$response -1
# keep a record of old stimulus values
ident.data$old.stimulus <- ident.data$stimulus
# change all "100" stimuli to 2 more than participant's maximum
with(ident.data, tapply(stimulus, subj, max))
max_stimuli <- with(ident.data[which(ident.data$stimulus!=100),], tapply(stimulus, subj, max))
max_stimuli <- data.frame(max_stimuli)
max_stimuli$subj <- row.names(max_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==100 & ident.data$subj==subj)] <- max_stimuli$max_stimuli[which(max_stimuli$subj==subj)] + 2
}
# change all "0" stimuli to 2 less than participant's minimum
min_stimuli <- with(ident.data[which(ident.data$stimulus!=0),], tapply(stimulus, subj, min))
min_stimuli <- data.frame(min_stimuli)
min_stimuli$subj <- row.names(min_stimuli)
for(subj in unique(ident.data$subj)){
if(subj != 11){
ident.data$stimulus[which(ident.data$stimulus==0 & ident.data$subj==subj)] <- min_stimuli$min_stimuli[which(min_stimuli$subj==subj)] - 2
}
}
with(ident.data, tapply(stimulus, subj, min))
# Read in identification data
text.files.identification <- dir("Identification_data/")
ident.data = data.frame(1,1,1,1,1,'NoPert')
names(ident.data) <- c("subj", "trial", "stimulus" , "response", "block", "session")
for(text_file in text.files.identification){
tmp <- read.table(file=paste("Identification_data/", text_file, sep=""), header = T)
if(length(grep("YESPERT", text_file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
ident.data <- rbind(ident.data, tmp)
}
ident.data = ident.data[-1,]
# move block down by one, so that block 0 is the pre-test
ident.data$block <- ident.data$block-1
# Convert to factors
ident.data$subj <- factor(ident.data$subj)
ident.data$trial <- factor(ident.data$trial)
ident.data$session <- factor(ident.data$session)
ident.data$block <- factor(ident.data$block)
# fix times when participants definitely hit the wrong button
ident.data$response[which(ident.data$response==2 & ident.data$stimulus == 0)] <- 1
ident.data$response[which(ident.data$response==1 & ident.data$stimulus == 100)] <- 2
# fix times when participants hit the number 3
ident.data$response[which(ident.data$response==3)] <- 2
# subtract 1 from the responses to make it 0 and 1
ident.data$response <- ident.data$response -1
# keep a record of old stimulus values
ident.data$old.stimulus <- ident.data$stimulus
# change all "100" stimuli to 2 more than participant's maximum
max_stimuli <- with(ident.data[which(ident.data$stimulus!=100),], tapply(stimulus, subj, max))
max_stimuli <- data.frame(max_stimuli)
max_stimuli$subj <- row.names(max_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==100 & ident.data$subj==subj)] <- max_stimuli$max_stimuli[which(max_stimuli$subj==subj)] + 2
}
# change all "0" stimuli to 2 less than participant's minimum
min_stimuli <- with(ident.data[which(ident.data$stimulus!=0),], tapply(stimulus, subj, min))
min_stimuli <- data.frame(min_stimuli)
min_stimuli$subj <- row.names(min_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==0 & ident.data$subj==subj)] <- min_stimuli$min_stimuli[which(min_stimuli$subj==subj)] - 2
}
with(ident.data, tapply(stimulus, subj, min))
head(ident.data)
str(ident.data)
# Copyright: Will Schuerman. Monday, October 13, 2014.
# Function to measure identification boundary for see_she_expr.
# File Description: For the specified block of data, interpolates 200 data points between the participant's actual responses and then attempts to fit a sigmoid-curve to the data, in order to identify the stimulus step corresponding to the perceptual boundary between "see" and "she."
# Packages:
require(drc)
# Function
MeasureIdent <- function(subj, block, sess){
d <- ident.data[which(ident.data$subj==subj &
ident.data$block==block &
ident.data$session==sess),]
steps <- sort(unique(d$stimulus[which(d$session==sess)]))
interpolated_steps <- approx(steps, n=200)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session==sess),],
tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
return(cbind(new_d$y, new_d$stimulus))
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
#model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
#return(model4$coefficients[[4]])
}
MeasureIdent(1,1,1)
MeasureIdent(subj = 1,1,"YesPert"
)
# Copyright: Will Schuerman. Monday, October 13, 2014.
# Function to measure identification boundary for see_she_expr.
# File Description: For the specified block of data, interpolates 200 data points between the participant's actual responses and then attempts to fit a sigmoid-curve to the data, in order to identify the stimulus step corresponding to the perceptual boundary between "see" and "she."
# Packages:
require(drc)
# Function
MeasureIdent <- function(subj, block, sess){
d <- ident.data[which(ident.data$subj==subj &
ident.data$block==block &
ident.data$session==sess),]
steps <- sort(unique(d$stimulus[which(d$session==sess)]))
interpolated_steps <- approx(steps, n=200)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session==sess),],
tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
return(cbind(new_d$y, new_d$stimulus))
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
return(model4$coefficients[[4]])
}
MeasureIdent(subj = 1,1,"YesPert"
)
# Copyright: Will Schuerman. Monday, October 13, 2014.
# Function to measure identification boundary for see_she_expr.
# File Description: For the specified block of data, interpolates 200 data points between the participant's actual responses and then attempts to fit a sigmoid-curve to the data, in order to identify the stimulus step corresponding to the perceptual boundary between "see" and "she."
# Packages:
require(drc)
# Function
MeasureIdent <- function(subj, block, sess){
d <- ident.data[which(ident.data$subj==subj &
ident.data$block==block &
ident.data$session==sess),]
steps <- sort(unique(d$stimulus[which(d$session==sess)]))
interpolated_steps <- approx(steps, n=200)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session==sess),],
tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
#return(cbind(new_d$y, new_d$stimulus))
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
return(model4$coefficients[[4]])
}
MeasureIdent(subj = 1,1,"YesPert")
help(drm)
??drm
??drc
require(drc)
install.packages("drc")
# Copyright: Will Schuerman. Monday, October 13, 2014.
# Function to measure identification boundary for see_she_expr.
# File Description: For the specified block of data, interpolates 200 data points between the participant's actual responses and then attempts to fit a sigmoid-curve to the data, in order to identify the stimulus step corresponding to the perceptual boundary between "see" and "she."
# Packages:
require(drc)
# Function
MeasureIdent <- function(subj, block, sess){
d <- ident.data[which(ident.data$subj==subj &
ident.data$block==block &
ident.data$session==sess),]
steps <- sort(unique(d$stimulus[which(d$session==sess)]))
interpolated_steps <- approx(steps, n=200)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session==sess),],
tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
#return(cbind(new_d$y, new_d$stimulus))
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
return(model4$coefficients[[4]])
}
MeasureIdent(subj = 1,1,"YesPert")
# plot_initial_attempt_2.R
PlotIdent <- function(subj, block = 1){
par(mfrow=c(2,2), oma=c(0,0,3,0))
d <- ident.data[which(ident.data$subj==subj & ident.data$block==block),]
steps <- sort(unique(d$stimulus[which(d$session=="NoPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "No Pert")
points(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)))),labels=steps)
# insert main plot title
mtext(paste(paste("Participant", subj), paste("Block", block)), outer=TRUE, cex=1.5)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
## yes pert
steps <- sort(unique(d$stimulus[which(d$session=="YesPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "Yes Pert")
points(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)))),labels=steps)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
}
PlotIdent(subj = 1,1,"YesPert")
PlotIdent(subj = 1,1)
PlotIdent(subj = 1,2)
PlotIdent(subj = 1,3)
PlotIdent(subj = 1,4)
PlotIdent(subj = 1,5)
head(ident.data)
with(ident.data, tapply(response, list(session, block), mnea))
with(ident.data, tapply(response, list(session, block), mean))
---
title: "sample_expr_readme"
author: "Will Schuerman"
date: "December 22, 2014"
output: html_document
---
### This project is based on experiments performed in collaboration between the Max Planck Institute for Psycholinguistics and the University of California, San Francisco. All data utilized in this script have been generated by the author for the purposes of demonstration.
This experiment examines
```{r}
with(ident.data, tapply(response, session, mean))
```
```{r}
summary(cars)
```
require(knitr)
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
par(mfrow=c(1,1))
### Plot Inbuffers and Outbuffers
plotBuffers <- function(data=prod.data, subject = "10", sess = "NoPert", plotbuff=TRUE, plotident=TRUE){
d <- prod.data[which((prod.data$subj== subject) & prod.data$session==sess),]
d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d <- droplevels(d)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
PlotBuffers(1,1,1)
par(mfrow=c(1,1))
### Plot Inbuffers and Outbuffers
PlotBuffers <- function(data=prod.data, subject = "10", sess = "NoPert", plotbuff=TRUE, plotident=TRUE){
d <- prod.data[which((prod.data$subj== subject) & prod.data$session==sess),]
d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d <- droplevels(d)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
PlotBuffers(1,1,1)
par(mfrow=c(1,1))
### Plot Inbuffers and Outbuffers
PlotBuffers <- function(data=prod.data, subject = "1", sess = "NoPert", plotbuff=TRUE, plotident=TRUE){
d <- prod.data[which((prod.data$subj== subject) & prod.data$session==sess),]
d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d <- droplevels(d)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
PlotBuffers()
# ddply to summarise identident.data
ident.summarized.data <- ddply(ident.data, c("subj", "block", "session"), summarise, mean(response))
# rename variable.
names(ident.summarized.data) <- c("subj", "block", "session", "proportion")
PlotBuffers()
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
PlotBuffers(sess=="YesPert")
PlotBuffers(sess=="YesPert")
PlotBuffers(sess=="YesPert")
devoff()
dev.off()
PlotBuffers(sess=="YesPert")
par(mfrow=c(1,1))
### Plot Inbuffers and Outbuffers
PlotBuffers <- function(data=prod.data, subject = "1", sess = "NoPert", plotbuff=TRUE, plotident=TRUE){
d <- prod.data[which((prod.data$subj== subject) & prod.data$session==sess),]
d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d.ident <- droplevels(d.ident)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
#return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
par(mfrow=c(2,1))
par(mfrow=c(2,1))
PlotBuffers(sess=="NoPert")
PlotBuffers(sess="YesPert")
