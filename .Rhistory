d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d.ident <- droplevels(d.ident)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
#return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
PlotBuffers(sess=="YesPert")
PlotBuffers(sess="YesPert")
with(ident.data, tapply(response, session, mean))
with(ident.data, tapply(response, block, mean))
with(ident.data, tapply(response, list(block, session), mean))
# Copyright: Will Schuerman. Monday, October 27th, 2014.
# File Description: Import production and identification data from compensation for coarticulation/altered auditory feedback experiment.
# Packages
require(plyr)
# Read in production data
text.files.production <- dir("Production_data/")
prod.data = data.frame(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,'x', 'x')
names(prod.data) <- c('in.f1.25', 'in.f2.25', 'out.f1.25', 'out.f2.25',
'in.f1.50', 'in.f2.50', 'out.f1.50', 'out.f2.50',
'in.f1.75', 'in.f2.75', 'out.f1.75', 'out.f2.75',
'block', 'trial', 'trialb', 'subj', 'session')
for(text.file in text.files.production){
tmp <- read.csv(file=paste("Production_data/",
text.file, sep=""),
header = FALSE)
tmp$trial = c(1:nrow(tmp))
tmp$trialb = rep(c(1:26), max(tmp$V13)+1)
tmp$subj <- substr(x = text.file,
start =1,
stop = regexpr(pattern = "_",
text.file)-1)
if(length(grep("YesPert", text.file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
names(tmp) <-c('in.f1.25', 'in.f2.25', 'out.f1.25', 'out.f2.25',
'in.f1.50', 'in.f2.50', 'out.f1.50', 'out.f2.50',
'in.f1.75', 'in.f2.75', 'out.f1.75', 'out.f2.75',
'block', 'trial', 'trialb', 'subj', 'session')
prod.data <- rbind(prod.data, tmp)
}
prod.data = prod.data[-1,]
# Increase raw block count to align with experiment procedure
prod.data$block = prod.data$block+1
# get rid of NaN trials
prod.data <- prod.data[complete.cases(prod.data),]
# get rid of 'S' in subject
prod.data$subj <- substr(prod.data$subj, start=2, stop=3)
prod.data$subj <- factor(prod.data$subj)
# Convert to factors
prod.data$subj <- factor(prod.data$subj)
prod.data$session <- factor(prod.data$session)
# restrict data to measurements taken at vowel midpoint.
prod.data <- prod.data[,c("subj", "session", "block","trialb","trial","in.f1.50","out.f1.50","in.f2.50","out.f2.50")]
# remove outliers, by scaling the the inbuffers and outbuffers, and discarding anything greater than 3 standard deviations from average
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.f2.50 = scale(in.f2.50))
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.f1.50 = scale(in.f1.50))
total.cases <- nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f1.50 < 3 &
prod.data$z.in.f1.50 > -3),]
f1.outliers <- total.cases - nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f2.50 < 3 &
prod.data$z.in.f2.50 > -3),]
f2.outliers <- total.cases-f1.outliers-nrow(prod.data)
# calculate dispersion between first and second resonant frequencies
prod.data$in.dispersion <- prod.data$in.f2.50 - prod.data$in.f1.50
prod.data$out.dispersion <- prod.data$out.f2.50 - prod.data$out.f1.50
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.dispersion = scale(in.dispersion))
# calculate baselines as average F1 and F2 in the first block.
prod.data$baseline.f1.50 <- 0
prod.data$baseline.f2.50 <- 0
prod.data$baseline.dispersion <- 0
for(session in levels(prod.data$session)){
for(subj in levels(prod.data$subj)){
prod.data$baseline.f1.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f1.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.f2.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f2.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.dispersion[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.dispersion'][which(prod.data$block==1)], na.rm=T)
}
}
# Read in identification data
text.files.identification <- dir("Identification_data/")
ident.data = data.frame(1,1,1,1,1,'NoPert')
names(ident.data) <- c("subj", "trial", "stimulus" , "response", "block", "session")
for(text_file in text.files.identification){
tmp <- read.table(file=paste("Identification_data/",
text_file,
sep=""),
header = T)
if(length(grep("YESPERT", text_file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
ident.data <- rbind(ident.data, tmp)
}
ident.data = ident.data[-1,]
# move block down by one, so that block 0 is the pre-test
ident.data$block <- ident.data$block-1
# Convert to factors
ident.data$subj <- factor(ident.data$subj)
ident.data$trial <- factor(ident.data$trial)
ident.data$session <- factor(ident.data$session)
ident.data$block <- factor(ident.data$block)
# fix times when participants definitely hit the wrong button
ident.data$response[which(ident.data$response==2 & ident.data$stimulus == 0)] <- 1
ident.data$response[which(ident.data$response==1 & ident.data$stimulus == 100)] <- 2
# fix times when participants hit the number 3
ident.data$response[which(ident.data$response==3)] <- 2
# subtract 1 from the responses to make it 0 and 1
ident.data$response <- ident.data$response -1
# keep a record of old stimulus values
ident.data$old.stimulus <- ident.data$stimulus
# change all "100" stimuli to 2 more than participant's maximum
max_stimuli <- with(ident.data[which(ident.data$stimulus!=100),],
tapply(stimulus, subj, max))
max_stimuli <- data.frame(max_stimuli)
max_stimuli$subj <- row.names(max_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==100 & ident.data$subj==subj)] <- max_stimuli$max_stimuli[which(max_stimuli$subj==subj)] + 2
}
# change all "0" stimuli to 2 less than participant's minimum
min_stimuli <- with(ident.data[which(ident.data$stimulus!=0),],
tapply(stimulus, subj, min))
min_stimuli <- data.frame(min_stimuli)
min_stimuli$subj <- row.names(min_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==0 & ident.data$subj==subj)] <- min_stimuli$min_stimuli[which(min_stimuli$subj==subj)] - 2
}
# summarise ident.data for use with plotting function
ident.summarized.data <- ddply(ident.data, c("subj", "block", "session"), summarise, mean(response))
# rename variable.
names(ident.summarized.data) <- c("subj", "block", "session", "proportion")
PlotBuffers(sess="YesPert")
knit2html("sample_expr_readme.Rmd")
# plot_initial_attempt_2.R
PlotIdent <- function(subj, block = 1){
par(mfrow=c(2,2), oma=c(0,0,3,0))
d <- ident.data[which(ident.data$subj==subj & ident.data$block==block),]
steps <- sort(unique(d$stimulus[which(d$session=="NoPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "No Pert")
points(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)))),labels=steps)
# insert main plot title
mtext(paste(paste("Participant", subj), paste("Block", block)), outer=TRUE, cex=1.5)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
## yes pert
steps <- sort(unique(d$stimulus[which(d$session=="YesPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "Yes Pert")
points(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)))),labels=steps)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
}
PlotIdent(1,3)
require(drc)
PlotIdent(1,3)
PlotIdent(1,4)
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
---
title: "sample_expr_readme"
author: "Will Schuerman"
date: "December 22, 2014"
output: html_document
---
### Experiment summary:
This project is based on experiments performed in collaboration between the Max Planck Institute for Psycholinguistics and the University of California, San Francisco. All data utilized in this script have been generated by the author for the purposes of demonstration.
### Overview of the experimental procedure.
In this experiment, the participant performed two tasks: a Production task and an Identification task. Each session began with an Identification task, followed by a Production task, followed by an Identification task, for a total of 4 Production tasks and 5 Identification tasks completed in each session. We predicted that exposure to altered auditory feedback would affect the identification of contextually-dependent speech sounds drawn from a computer generated continuuum.
In the Production task, the participant was presented with 26 words containing the vowel /i/ and asked to read them aloud. In the first session ("NoPert"), the participant heard their unaltered voice via headphones. In the second session ("YesPert"), the resonating frequencies of the participants voice were shifted backwards in the vowel space. The shift occurred slowly to prevent the participant from noticing. The shift began on the first trial of the second block, slowly increasing until the last trial of the second block. The shift then persisted at full strength for the following two blocks.
In the Identification task, the participant was asked identify via keyboard whether they heard a speaker producing the word "see" (response button 1) or the word "she" (response button 2). The presented stimuli were drawn from a continuum between "see" and "she", generated via additive synthesis.
### Results
The graphs below show the measurements for the first and second resonant frequencies of the voice over the course of the experiment. Red crosses represent what the participant actually produced, while blue crosses indicate the frequency of the auditory feedback transmitted over headphones (what the participant heard themselves saying). The solid line indicates the mean of the first production block, and is utilized as a baseline of comparison for all subsequent production blocks.
The large circles indicate the proportion of "she" responses obtained during the identification tasks before and after each production block.
In the first (NoPert) session, input and output are identical throughout the experiment.
```{r, echo=FALSE}
PlotBuffers(sess="NoPert")
```
In the second (YesPert) session, the first frequency is shifted upwards (higher than normal) and the second frequency is shifted downwards (lower than normal). Decreasing the dispersion between these two frequencies results in a vowel that sounds more rounded and farther back in the vowelspace than the speaker intended.
```{r, echo=FALSE}
PlotBuffers(sess="YesPert")
```
These graphs show that in the first session, the participant experienced a steady decrease in the number of stimuli perceived as "she." In the second session, the proportion of "she" responses remains relatively stable.
Another method of comparing performance in the two sessions is to determine the stimulus number at which the participant switched from reporting hearing "see" to reporting hearing "she".
The graph below contrasts performance in "Block 4" of each session. The first column shows the participant's responses to each stimulus, indicated by the black circles. Red asterisks represent linearly interpolated data points between the participant's responses. The second column shows the results of fitting a sigmoid-curve to the interpolated responses. The dotted line indicates the 50% response point, i.e. the stimulus number at which the participant stopped hearing "see" and started hearing "she".
```{r, echo=FALSE}
PlotIdent(1,4)
```
These results suggest that, for this participant, there was no effect of altered auditory feedback on the interwoven identification tasks.
knit2html("sample_expr_readme.Rmd")
knit2html("sample_expr_readme.Rmd")
# Plot Identification Boundary
PlotIdent <- function(subj, block = 1){
par(mfrow=c(2,2), oma=c(0,0,3,0))
d <- ident.data[which(ident.data$subj==subj & ident.data$block==block),]
steps <- sort(unique(d$stimulus[which(d$session=="NoPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "No Pert")
points(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)))),labels=steps)
# insert main plot title
mtext(paste(paste("Participant", subj), paste("Block", block)), outer=TRUE, cex=1.5)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="NoPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
## yes pert
steps <- sort(unique(d$stimulus[which(d$session=="YesPert")]))
interpolated_steps <- approx(steps, n=200)
# plot original and interpolated responses
plot(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), ylab="response", xaxt='n', main = "Yes Pert")
points(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200), pch="*", col =2)
axis(side=1, at=c(1:length(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)))),labels=steps)
# create data frame of interpolated responses
new_d = data.frame(approx(with(d[which(d$session=="YesPert"),], tapply(response, stimulus, mean)), n=200))
new_d$stimulus <- interpolated_steps$y
# fitting 4-parameter log-logistic model
# Coefficients: b = slope, c = lower limit, d = upper limit, e = half-way between upper limit and lower limit
model4 <- drm(y~stimulus, data=new_d, fct=LL.4())
plot(predict(model4),xaxt='n', ylim=c(0,1), main = round(model4$coefficients[4]))
axis(side=1, at=c(1:200),labels=round(new_d$stimulus))
abline(0.5, 0, lty='dashed')
}
# Plot Inbuffers and Outbuffers
PlotBuffers <- function(data=prod.data, subject = "1", sess = "NoPert", plotbuff=TRUE, plotident=TRUE){
d <- prod.data[which((prod.data$subj== subject) & prod.data$session==sess),]
d <- droplevels(d)
meanF1 <- mean(d[,'in.f1.50'], na.rm=T)
meanF2 <- mean(d[,'in.f2.50'], na.rm=T)
sdF1 <- sd(d[,'in.f1.50'], na.rm=T)
sdF2 <- sd(d[,'in.f2.50'], na.rm=T)
d <- d[which(d[,'in.f1.50'] < meanF1 + 2*sdF1 & d[,'in.f1.50'] > meanF1 - 2*sdF1),]
d <- d[which(d[,'in.f2.50'] < meanF2 + 2*sdF2 & d[,'in.f2.50'] > meanF2 - 2*sdF2),]
f1Baseline = mean(d[,'in.f1.50'][which(d$block==1)], na.rm=T)
f2Baseline = mean(d[,'in.f2.50'][which(d$block==1)], na.rm=T)
block.size= max(d$trial)/max(d$block)
#create plots with baselines
if(plotbuff==TRUE){
plot(c(1,max(d$trial)), c(0, 3500), type='n', xlab="trial", ylab="frequency", main=sess)
points(d$trial, d[,'in.f1.50'], col='red')
points(d$trial, d[,'in.f2.50'], col = 'red', pch=3)
abline(h=f1Baseline)
abline(lm(d[,'in.f1.50']~trial, data=d), lty="dashed")
points(d$trial, d[,'out.f1.50'], col='blue')
points(d$trial, d[,'out.f2.50'], col='blue', pch=3)
abline(h=f2Baseline)
abline(lm(d[,'in.f2.50']~trial, data=d), lty="dashed")
abline(v=block.size, lty="dotted")
abline(v=block.size*2, lty="dotted")
abline(v=block.size*3, lty="dotted")
if(max(d$block) > 3 ){
abline(v=block.size*4, lty="dotted")
abline(v=block.size*5, lty="dotted")
}
}
# add identification data
if(plotident==TRUE){
par(new=T)
d.ident <- ident.summarized.data[which(ident.summarized.data$subj==subject & ident.summarized.data$session==sess),]
d.ident <- droplevels(d.ident)
plot(d.ident$proportion, xlab=NA, ylab=NA, axes=F, ylim=c(0,1), cex=3)
axis(side=4)
lines(d.ident$proportion, xlab=NA, ylab=NA, ylim=c(0,1), cex=3)
}
# measure difference between inbuffer and baseline
#return(cbind( with(d, tapply(in.f1.50, block, mean)) -f1Baseline, with(d, tapply(in.f2.50, block, mean))-f2Baseline))
}
# Copyright: Will Schuerman. Monday, October 27th, 2014.
# File Description: Import production and identification data from compensation for coarticulation/altered auditory feedback experiment.
# Packages
require(plyr)
# Read in production data
text.files.production <- dir("Production_data/")
prod.data = data.frame(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,'x', 'x')
names(prod.data) <- c('in.f1.25', 'in.f2.25', 'out.f1.25', 'out.f2.25',
'in.f1.50', 'in.f2.50', 'out.f1.50', 'out.f2.50',
'in.f1.75', 'in.f2.75', 'out.f1.75', 'out.f2.75',
'block', 'trial', 'trialb', 'subj', 'session')
for(text.file in text.files.production){
tmp <- read.csv(file=paste("Production_data/",
text.file, sep=""),
header = FALSE)
tmp$trial = c(1:nrow(tmp))
tmp$trialb = rep(c(1:26), max(tmp$V13)+1)
tmp$subj <- substr(x = text.file,
start =1,
stop = regexpr(pattern = "_",
text.file)-1)
if(length(grep("YesPert", text.file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
names(tmp) <-c('in.f1.25', 'in.f2.25', 'out.f1.25', 'out.f2.25',
'in.f1.50', 'in.f2.50', 'out.f1.50', 'out.f2.50',
'in.f1.75', 'in.f2.75', 'out.f1.75', 'out.f2.75',
'block', 'trial', 'trialb', 'subj', 'session')
prod.data <- rbind(prod.data, tmp)
}
prod.data = prod.data[-1,]
# Increase raw block count to align with experiment procedure
prod.data$block = prod.data$block+1
# get rid of NaN trials
prod.data <- prod.data[complete.cases(prod.data),]
# get rid of 'S' in subject
prod.data$subj <- substr(prod.data$subj, start=2, stop=3)
prod.data$subj <- factor(prod.data$subj)
# Convert to factors
prod.data$subj <- factor(prod.data$subj)
prod.data$session <- factor(prod.data$session)
# restrict data to measurements taken at vowel midpoint.
prod.data <- prod.data[,c("subj", "session", "block","trialb","trial","in.f1.50","out.f1.50","in.f2.50","out.f2.50")]
# remove outliers, by scaling the the inbuffers and outbuffers, and discarding anything greater than 3 standard deviations from average
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.f2.50 = scale(in.f2.50))
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.f1.50 = scale(in.f1.50))
total.cases <- nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f1.50 < 3 &
prod.data$z.in.f1.50 > -3),]
f1.outliers <- total.cases - nrow(prod.data)
prod.data <- prod.data[which(prod.data$z.in.f2.50 < 3 &
prod.data$z.in.f2.50 > -3),]
f2.outliers <- total.cases-f1.outliers-nrow(prod.data)
# calculate dispersion between first and second resonant frequencies
prod.data$in.dispersion <- prod.data$in.f2.50 - prod.data$in.f1.50
prod.data$out.dispersion <- prod.data$out.f2.50 - prod.data$out.f1.50
prod.data <- ddply(prod.data,
c("subj", "session"),
transform,
z.in.dispersion = scale(in.dispersion))
# calculate baselines as average F1 and F2 in the first block.
prod.data$baseline.f1.50 <- 0
prod.data$baseline.f2.50 <- 0
prod.data$baseline.dispersion <- 0
for(session in levels(prod.data$session)){
for(subj in levels(prod.data$subj)){
prod.data$baseline.f1.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f1.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.f2.50[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.f2.50'][which(prod.data$block==1)], na.rm=T)
prod.data$baseline.dispersion[which(prod.data$session==session & prod.data$subj==subj)] <- mean(prod.data[which(prod.data$session==session & prod.data$subj==subj),'in.dispersion'][which(prod.data$block==1)], na.rm=T)
}
}
# Read in identification data
text.files.identification <- dir("Identification_data/")
ident.data = data.frame(1,1,1,1,1,'NoPert')
names(ident.data) <- c("subj", "trial", "stimulus" , "response", "block", "session")
for(text_file in text.files.identification){
tmp <- read.table(file=paste("Identification_data/",
text_file,
sep=""),
header = T)
if(length(grep("YESPERT", text_file))>0){
tmp$session <- "YesPert"
}else{
tmp$session <- "NoPert"
}
ident.data <- rbind(ident.data, tmp)
}
ident.data = ident.data[-1,]
# move block down by one, so that block 0 is the pre-test
ident.data$block <- ident.data$block-1
# Convert to factors
ident.data$subj <- factor(ident.data$subj)
ident.data$trial <- factor(ident.data$trial)
ident.data$session <- factor(ident.data$session)
ident.data$block <- factor(ident.data$block)
# fix times when participants definitely hit the wrong button
ident.data$response[which(ident.data$response==2 & ident.data$stimulus == 0)] <- 1
ident.data$response[which(ident.data$response==1 & ident.data$stimulus == 100)] <- 2
# fix times when participants hit the number 3
ident.data$response[which(ident.data$response==3)] <- 2
# subtract 1 from the responses to make it 0 and 1
ident.data$response <- ident.data$response -1
# keep a record of old stimulus values
ident.data$old.stimulus <- ident.data$stimulus
# change all "100" stimuli to 2 more than participant's maximum
max_stimuli <- with(ident.data[which(ident.data$stimulus!=100),],
tapply(stimulus, subj, max))
max_stimuli <- data.frame(max_stimuli)
max_stimuli$subj <- row.names(max_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==100 & ident.data$subj==subj)] <- max_stimuli$max_stimuli[which(max_stimuli$subj==subj)] + 2
}
# change all "0" stimuli to 2 less than participant's minimum
min_stimuli <- with(ident.data[which(ident.data$stimulus!=0),],
tapply(stimulus, subj, min))
min_stimuli <- data.frame(min_stimuli)
min_stimuli$subj <- row.names(min_stimuli)
for(subj in unique(ident.data$subj)){
ident.data$stimulus[which(ident.data$stimulus==0 & ident.data$subj==subj)] <- min_stimuli$min_stimuli[which(min_stimuli$subj==subj)] - 2
}
# summarise ident.data for use with plotting function
ident.summarized.data <- ddply(ident.data, c("subj", "block", "session"), summarise, mean(response))
# rename variable.
names(ident.summarized.data) <- c("subj", "block", "session", "proportion")
---
title: "sample_expr_readme"
author: "Will Schuerman"
date: "December 22, 2014"
output: html_document
---
### Experiment summary:
This project is based on experiments performed in collaboration between the Max Planck Institute for Psycholinguistics and the University of California, San Francisco. All data utilized in this script have been generated by the author for the purposes of demonstration.
### Overview of the experimental procedure.
In this experiment, the participant performed two tasks: a Production task and an Identification task. Each session began with an Identification task, followed by a Production task, followed by an Identification task, for a total of 4 Production tasks and 5 Identification tasks completed in each session. We predicted that exposure to altered auditory feedback would affect the identification of contextually-dependent speech sounds drawn from a computer generated continuuum.
In the Production task, the participant was presented with 26 words containing the vowel /i/ and asked to read them aloud. In the first session ("NoPert"), the participant heard their unaltered voice via headphones. In the second session ("YesPert"), the resonating frequencies of the participants voice were shifted backwards in the vowel space. The shift occurred slowly to prevent the participant from noticing. The shift began on the first trial of the second block, slowly increasing until the last trial of the second block. The shift then persisted at full strength for the following two blocks.
In the Identification task, the participant was asked identify via keyboard whether they heard a speaker producing the word "see" (response button 1) or the word "she" (response button 2). The presented stimuli were drawn from a continuum between "see" and "she", generated via additive synthesis.
### Results
The graphs below show the measurements for the first and second resonant frequencies of the voice over the course of the experiment. Red crosses represent what the participant actually produced, while blue crosses indicate the frequency of the auditory feedback transmitted over headphones (what the participant heard themselves saying). The solid line indicates the mean of the first production block, and is utilized as a baseline of comparison for all subsequent production blocks.
The large circles indicate the proportion of "she" responses obtained during the identification tasks before and after each production block.
In the first (NoPert) session, input and output are identical throughout the experiment.
```{r, echo=FALSE}
PlotBuffers(sess="NoPert")
```
In the second (YesPert) session, the first frequency is shifted upwards (higher than normal) and the second frequency is shifted downwards (lower than normal). Decreasing the dispersion between these two frequencies results in a vowel that sounds more rounded and farther back in the vowelspace than the speaker intended.
```{r, echo=FALSE}
PlotBuffers(sess="YesPert")
```
These graphs show that in the first session, the participant experienced a steady decrease in the number of stimuli perceived as "she." In the second session, the proportion of "she" responses remains relatively stable.
Another method of comparing performance in the two sessions is to determine the stimulus number at which the participant switched from reporting hearing "see" to reporting hearing "she".
The graph below contrasts performance in "Block 4" of each session. The first column shows the participant's responses to each stimulus, indicated by the black circles. Red asterisks represent linearly interpolated data points between the participant's responses. The second column shows the results of fitting a sigmoid-curve to the interpolated responses. The dotted line indicates the 50% response point, i.e. the stimulus number at which the participant stopped hearing "see" and started hearing "she".
```{r, echo=FALSE}
PlotIdent(1,4)
```
These results suggest that, for this participant, there was no effect of altered auditory feedback on the interwoven identification tasks.
knit2html("sample_expr_readme.Rmd")
require(kntr)
require(knitr)
require(knitr)
knit2html("sample_expr_readme.Rmd")
glm(response~block, data=ident.data)
summary(glm(response~block, data=ident.data, family="binomial"))
summary(glm(response~block*session, data=ident.data, family="binomial"))
